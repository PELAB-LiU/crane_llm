# Executed Cells:
## Cell 1:

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from matplotlib import pyplot as plt

## Cell 2:

import pathlib
data_dir = 'data/web_scraped_small'
data_dir = pathlib.Path(data_dir).with_suffix('')

## Cell 3:

image_count = len(list(data_dir.glob('*/*.jpg')))
image_count

## Cell 4:

import PIL
princess = list(data_dir.glob('princess/*'))
PIL.Image.open(str(princess[1]))

## Cell 5:

image_height, image_width = PIL.Image.open(str(princess[1])).size
batch_size,epochs = 64,10

## Cell 6:

train_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset='training',
    image_size=(image_height, image_width),
    seed = 1,
    shuffle=True,
    batch_size=batch_size
)

## Cell 7:

val_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset='validation',
    image_size=(image_height, image_width),
    seed = 1,
    shuffle=True,
    batch_size=batch_size
)

## Cell 8:

normalization_layer = layers.Rescaling(1./255)

## Cell 9:

from tensorflow import keras
data_augmentation = keras.Sequential(
  [
    layers.RandomFlip("horizontal",
                      input_shape=(image_height,
                                  image_width,
                                  3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

## Cell 10:

num_of_classes = len(train_ds.class_names)
num_of_classes

## Cell 11:

model = Sequential([
  data_augmentation,
  normalization_layer,
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.2),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_of_classes, name="outputs")
])

## Cell 12:

model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

# Current relevent runtime information:
{'__method__model_fit': {'type': "<class 'method'>"},
 'model': {'execution_cell_source': {'cellno': 14, 'lineno': 1},
           'type': "<class 'keras.src.models.sequential.Sequential'>"},
 'train_ds': {'element_spec': '(TensorSpec(shape=(None, 600, 472, 3), '
                              'dtype=tf.float32, name=None), '
                              'TensorSpec(shape=(None,), dtype=tf.int32, '
                              'name=None))',
              'execution_cell_source': {'cellno': 7, 'lineno': 1},
              'type': 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'},
 'val_ds': {'element_spec': '(TensorSpec(shape=(None, 600, 472, 3), '
                            'dtype=tf.float32, name=None), '
                            'TensorSpec(shape=(None,), dtype=tf.int32, '
                            'name=None))',
            'execution_cell_source': {'cellno': 8, 'lineno': 1},
            'type': 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'}}
# Target Cell:

history = model.fit(train_ds,validation_data=val_ds, epochs=1)