# Executed Cells:
## Cell 1:

from collections import Counter
import cv2
import os
import glob
import skimage
import numpy as np
import pandas as pd
import seaborn as sn
import preprocessing
from tqdm import tqdm
from io import BytesIO
from PIL import Image
from os import listdir
import matplotlib.pyplot as plt
from imageio import imread
from skimage.transform import resize
from collections import Counter
import IPython.display as display

sn.set()

from sklearn.svm import SVC
from sklearn import metrics
from sklearn.utils import shuffle
from xgboost import XGBClassifier
from sklearn import metrics
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils import compute_class_weight
from sklearn.preprocessing import MinMaxScaler,LabelBinarizer
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.metrics import AUC
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.applications.nasnet import NASNetMobile
from tensorflow.keras.applications.densenet import DenseNet169
from tensorflow.keras.applications.densenet import DenseNet121
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

## Cell 2:

InputPath = 'data/images-after-converted_small/'
CsvPath   = 'data/breast-level_annotations (1).csv.zip'

## Cell 3:

df = pd.read_csv(CsvPath)
df.head(3)

## Cell 4:

X= []
y=[]

## Cell 5:

import imageio
for i in range(df.shape[0]):

    path = InputPath+df.laterality[i]+'-'+df.view_position[i]+'/'+df.image_id[i]+'.png'
    if os.path.exists(path):
        img = cv2.imread(path,0)
        img_size = cv2.resize(img, (100, 100), interpolation = cv2.INTER_LINEAR)


        X.append(img_size)

        y.append(df.breast_birads[i])

## Cell 6:

Y = []
import re
for i in y:
    Y.append(int(re.sub("[A-Z]+\-[A-Z]+", "", i)))

## Cell 7:

X = np.array(X)

## Cell 8:

Y = np.array(Y)

## Cell 9:

train_images, val_images, train_labels, val_labels=train_test_split(X, Y,
                                                                      test_size=0.3, random_state=42)
val_images,test_images, val_labels, test_labels=train_test_split(val_images, val_labels,
                                                                      test_size=0.33, random_state=42)


print('Number of   training samples : {}'.format(train_images.shape[0]))
print('Number of validation samples : {}'.format(val_images.shape[0]))
print('Number of       test samples : {}'.format(test_images.shape[0]))

## Cell 10:

from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , MaxPooling2D, BatchNormalization
from tensorflow.keras.optimizers import Adam
model = Sequential(name = 'VGG19')

model.add(Conv2D(input_shape = (100, 100,3), filters = 64, kernel_size = (3,3), padding = 'same',
                 activation = 'relu'))
model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))

model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))

model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))

model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))

model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = 'same', activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))

model.add(Flatten())
model.add(Dense(units = 4096, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(units = 4096, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(20, activation = 'softmax'))

model.compile(optimizer=Adam(0.00001), loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])
model.summary()

# Current relevent runtime information:
{'__method__model_fit': {'type': "<class 'method'>"},
 'model': {'execution_cell_source': {'cellno': 9, 'lineno': 3},
           'type': "<class 'keras.src.models.sequential.Sequential'>"},
 'train_images': {'dtype': 'uint8',
                  'has_nan': False,
                  'shape': (56, 100, 100),
                  'type': 'numpy.ndarray',
                  'value_range': (0, 255)},
 'train_labels': {'dtype': 'int64',
                  'has_nan': False,
                  'shape': (56,),
                  'type': 'numpy.ndarray',
                  'value_info': {'num_unique': 4,
                                 'unique_values': [1, 2, 3, 4],
                                 'value_type': 'categorical numeric(no more '
                                               'than 10 unique values)'},
                  'value_range': (1, 4)},
 'val_images': {'dtype': 'uint8',
                'has_nan': False,
                'shape': (16, 100, 100),
                'type': 'numpy.ndarray',
                'value_range': (0, 255)},
 'val_labels': {'dtype': 'int64',
                'has_nan': False,
                'shape': (16,),
                'type': 'numpy.ndarray',
                'value_info': {'num_unique': 3,
                               'unique_values': [1, 2, 3],
                               'value_type': 'categorical numeric(no more than '
                                             '10 unique values)'},
                'value_range': (1, 3)}}
# Target Cell:

history = model.fit(train_images, train_labels, batch_size = 16, epochs=2, validation_data=(val_images, val_labels), verbose = 1)