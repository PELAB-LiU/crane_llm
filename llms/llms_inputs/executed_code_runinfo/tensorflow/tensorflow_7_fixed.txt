# Executed Cells:
## Cell 1:

import tensorflow as tf

import matplotlib.pyplot as plt
import numpy as np
from transformers import BertTokenizer, TFBertModel

## Cell 2:

try:
    tpu=tf.distribute.cluster_resolver.TCPClusterResolver()


    print("Device : ",tpu.master())
    tf.config.experimental_connect_to_cluster(tpu)

    tf.tpu.experimental.initialize_tpu_system(tpu)

    strategy=tf.distribute.experimental.TPUStrategy(tpu)

except:
    strategy=tf.distribute.get_strategy()


print("Number of replicas : ",strategy.num_replicas_in_sync)



print(tf.__version__)







## Cell 3:

import pandas as pd

train = pd.read_csv("data/train.csv")
train = train[:10]

## Cell 4:

model_name = 'bert-base-multilingual-cased'
tokenizer = BertTokenizer.from_pretrained(model_name)

## Cell 5:

def encode_sentence(s):
   tokens = list(tokenizer.tokenize(s))
   tokens.append('[SEP]')
   return tokenizer.convert_tokens_to_ids(tokens)

## Cell 6:

def bert_encode(hypotheses, premises, tokenizer):

  num_examples = len(hypotheses)

  sentence1 = tf.ragged.constant([
      encode_sentence(s)
      for s in np.array(hypotheses)])
  sentence2 = tf.ragged.constant([
      encode_sentence(s)
       for s in np.array(premises)])

  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]
  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)

  input_mask = tf.ones_like(input_word_ids).to_tensor()

  type_cls = tf.zeros_like(cls)
  type_s1 = tf.zeros_like(sentence1)
  type_s2 = tf.ones_like(sentence2)
  input_type_ids = tf.concat(
      [type_cls, type_s1, type_s2], axis=-1).to_tensor()

  inputs = {
      'input_word_ids': input_word_ids.to_tensor(),
      'input_mask': input_mask,
      'input_type_ids': input_type_ids}

  return inputs

## Cell 7:

train_input = bert_encode(train.premise.values, train.hypothesis.values, tokenizer)

## Cell 8:



max_len = train_input['input_word_ids'].shape[1]

from transformers import BertTokenizer, TFBertModel


def build_model():
    bert_encoder = TFBertModel.from_pretrained(model_name)
    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name="input_word_ids")
    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name="input_mask")
    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name="input_type_ids")

    embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]
    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])

    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)
    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    return model

## Cell 9:

with strategy.scope():
    model = build_model()
    model.summary()

# Current relevent runtime information:
{'__method__train_label': {'type': "<class 'pandas.core.series.Series'>",
                           'value_info': {'num_unique': 3,
                                          'unique_values': [0, 1, 2],
                                          'value_type': 'categorical '
                                                        'numeric(no more than '
                                                        '10 unique values)'}},
 'train': {'execution_cell_source': {'cellno': 13, 'lineno': 4},
           'has_nan': False,
           'per_column': {'hypothesis': {'example_values': ['The rules '
                                                            'developed ...',
                                                            'Practice groups '
                                                            'are ...',
                                                            "J'essayais "
                                                            "d'accompl...",
                                                            "They can't defend "
                                                            'th...',
                                                            'เด็กสามารถเห็นได้ว่า...'],
                                         'num_unique': 10,
                                         'type': 'categorical'},
                          'id': {'example_values': ['5130fd2cb5',
                                                    '5b72532a0b',
                                                    '3931fbe82a',
                                                    '5622f0c60b',
                                                    '86aaa48b45'],
                                 'num_unique': 10,
                                 'type': 'categorical'},
                          'label': {'num_unique': 3,
                                    'type': 'categorical_numeric',
                                    'value_range': (0, 2)},
                          'lang_abv': {'example_values': ['en',
                                                          'fr',
                                                          'th',
                                                          'tr',
                                                          'ur'],
                                       'num_unique': 6,
                                       'type': 'categorical'},
                          'language': {'example_values': ['English',
                                                          'French',
                                                          'Thai',
                                                          'Turkish',
                                                          'Urdu'],
                                       'num_unique': 6,
                                       'type': 'categorical'},
                          'premise': {'example_values': ['and these comments '
                                                         'w...',
                                                         'These are issues '
                                                         'tha...',
                                                         'Des petites choses '
                                                         'c...',
                                                         "you know they can't "
                                                         '...',
                                                         'ในการเล่นบทบาทสมมุติ...'],
                                      'num_unique': 10,
                                      'type': 'categorical'}},
           'shape': (10, 6),
           'type': 'pandas.core.frame.DataFrame'},
 'train_input': {'execution_cell_source': {'cellno': 52, 'lineno': 1},
                 'length': 3,
                 'preview': [{'key': 'input_word_ids',
                              'key_type': "<class 'str'>",
                              'value_repr': '<tf.Tensor: shape=(10, 172), '
                                            'dtype=int32, numpy=\n'
                                            'a...',
                              'value_type': '<class '
                                            "'tensorflow.python.framework.ops.EagerTensor'>"},
                             {'key': 'input_mask',
                              'key_type': "<class 'str'>",
                              'value_repr': '<tf.Tensor: shape=(10, 172), '
                                            'dtype=int32, numpy=\n'
                                            'a...',
                              'value_type': '<class '
                                            "'tensorflow.python.framework.ops.EagerTensor'>"},
                             {'key': 'input_type_ids',
                              'key_type': "<class 'str'>",
                              'value_repr': '<tf.Tensor: shape=(10, 172), '
                                            'dtype=int32, numpy=\n'
                                            'a...',
                              'value_type': '<class '
                                            "'tensorflow.python.framework.ops.EagerTensor'>"}],
                 'type': "<class 'dict'>"}}
# Target Cell:

model.fit(train_input, train.label.values, epochs = 2, verbose = 1, batch_size = 64, validation_split = 0.2)