# Executed Cells:
## Cell 1:

import json
import matplotlib.pyplot as plt
import numpy as np
from IPython.display import clear_output
from qiskit import QuantumCircuit
from qiskit.circuit import ParameterVector
from qiskit.circuit.library import ZFeatureMap
from qiskit.quantum_info import SparsePauliOp
from qiskit_algorithms.optimizers import COBYLA
from qiskit_algorithms.utils import algorithm_globals
from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier
from qiskit_machine_learning.neural_networks import EstimatorQNN
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np
import pyarrow.parquet as pq
import pandas as pd



import numpy as np
import matplotlib.pyplot as plt

from torch import Tensor
from torch.nn import Linear, CrossEntropyLoss, MSELoss
from torch.optim import LBFGS

from qiskit import QuantumCircuit
from qiskit.circuit import Parameter
from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap
from qiskit_algorithms.utils import algorithm_globals
from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN
from qiskit_machine_learning.connectors import TorchConnector


algorithm_globals.random_seed = 42

import torch
from torch import cat, no_grad, manual_seed
from torch.utils.data import DataLoader,Dataset
from torchvision import datasets, transforms
import torch.optim as optim
from torch.nn import (
    Module,
    Conv2d,
    Linear,
    Dropout2d,
    NLLLoss,
    MaxPool2d,
    Flatten,
    Sequential,
    ReLU,
)
import torch.nn.functional as F

## Cell 2:

import numpy as np
import pandas as pd
import pyarrow.parquet as pq
import matplotlib.pyplot as plt


def to_3d(arr):
    douaa = []
    for i in range(0, 3):
        dou = np.stack(np.stack(arr)[i], axis=-1)
        douaa.append(dou)
    douaa = np.array(douaa)
    return douaa


parquet_file_path = 'data/QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet'
parquet_file = pq.ParquetFile(parquet_file_path)


total_rows = parquet_file.metadata.num_rows


images_array = []
labels_array = []


chunk_size = 50
for i in range(0, total_rows, chunk_size):

    chunk = parquet_file.read_row_group(i)
    df = chunk.to_pandas()


    chunk_images_array = []
    chunk_labels_array = []


    for j in range(len(df)):

        df['X_jets'][j] = to_3d(df['X_jets'][j].copy())


        chunk_images_array.append(df['X_jets'][j])
        chunk_labels_array.append(df['y'][j])


    images_array.extend(chunk_images_array)
    labels_array.extend(chunk_labels_array)


images_array = np.array(images_array)
labels_array = np.array(labels_array)

## Cell 3:

train_images, test_images, train_labels, test_labels = train_test_split(
    images_array, labels_array, test_size=0.3
)

print(train_images.shape)
print(train_labels.shape)

## Cell 4:


import numpy as np
import matplotlib.pyplot as plt



reduced_images_array = np.mean(train_images, axis=1)


num_images_to_plot = 1
for i in range(num_images_to_plot):
    plt.imshow(reduced_images_array[i], cmap='gray')
    plt.title(f"Label: {labels_array[i]}")
    plt.show()

## Cell 5:

import numpy as np
from scipy.ndimage import zoom





target_shape = (125, 125)


resized_images = np.zeros((reduced_images_array.shape[0], *target_shape))


for i in range(reduced_images_array.shape[0]):
    resized_images[i] = zoom(reduced_images_array[i], (target_shape[0] / reduced_images_array.shape[1], target_shape[1] / reduced_images_array.shape[2]))


print(resized_images.shape)

## Cell 6:

import torch

import torch
from torchvision import transforms


resized_images = resized_images.astype(np.float32)
train_labels = train_labels.astype(np.float32)

transform = transforms.Compose([
    transforms.ToTensor(),
])


tensor_images = torch.stack([transform(img) for img in resized_images])

label_transform = transforms.Compose([
    transforms.Lambda(lambda x: torch.tensor(x, dtype=torch.float32)),
])


tensor_labels = label_transform(train_labels).long()








class CustomDataset(Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        return self.images[idx], self.labels[idx]

batch_size = 1
shuffle = True

custom_dataset = CustomDataset(tensor_images, tensor_labels)
train_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=shuffle)

# Target Cell:

plt.imshow(custom_dataset.images[1][0, :, :])
plt.imshow(custom_dataset.labels[0])

plt.title(f"Label: {labels_array[1]}")
plt.show()