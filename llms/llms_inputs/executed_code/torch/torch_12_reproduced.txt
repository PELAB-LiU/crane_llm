# Executed Cells:
## Cell 1:





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import plotly.graph_objs as go
import plotly.offline as py
import plotly.express as px


import warnings
warnings.filterwarnings('ignore')




import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))




## Cell 2:



from transformers import AutoTokenizer

df = pd.read_csv('data/train.csv')

tokenizer = AutoTokenizer.from_pretrained("gpt2")


df.drop_duplicates(inplace=True)
df.dropna(subset=['output', 'instruction'], inplace=True)


df['instruction_tokens'] = df['instruction'].apply(lambda x: len(tokenizer.tokenize(x)))
df['output_tokens'] = df['output'].apply(lambda x: len(tokenizer.tokenize(x)))


print(df.head())

# Target Cell:

import pandas as pd
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer


model_name = "gpt2"
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)



generated_responses = []

for index, row in df.iterrows():
    prompt = row['instruction']
    input_ids = tokenizer.encode(prompt, return_tensors="pt")


    with torch.no_grad():
        output = model.generate(
            input_ids,
            max_length=input_ids.size(1) + 50,
            num_return_sequences=1,
            pad_token_id=tokenizer.eos_token_id,
            attention_mask=input_ids.ne(tokenizer.pad_token_id)
        )


    padded_output = output[:, input_ids.size(1):]

    response = tokenizer.decode(padded_output[0], skip_special_tokens=True)
    generated_responses.append(response)