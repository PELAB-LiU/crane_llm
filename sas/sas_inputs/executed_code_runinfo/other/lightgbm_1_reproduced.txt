# Executed Cells:
## Cell 1:

import numpy as np
import pandas as pd

## Cell 2:

class conf:
    index = 'Id'
    target = 'quality'
    random = 2023

    load_original = True
    only_positive = False

    include_optuna = False

    include_lgbm = False
    include_catboost = False
    include_lgbm_regression = True
    n_trials = 10

np.random.seed(conf.random)

## Cell 3:

import matplotlib.pyplot as plt
import seaborn as sns
from pandas.plotting import scatter_matrix

## Cell 4:

train_full = pd.read_csv("data/train.csv", index_col=conf.index)
test_full = pd.read_csv("data/test.csv", index_col=conf.index)
train = train_full.copy()
test = test_full.copy()
if conf.load_original:
    print("Load external data...")
    original = pd.read_csv('data/WineQT.csv', index_col=conf.index)
    if conf.only_positive:
        train = pd.concat([original[original[conf.target] == 1], train_full], ignore_index=True)
    else:
        train = pd.concat([original, train_full])

train.info()

## Cell 5:

train = train.reset_index()
train = train.drop(columns=['Id'])

## Cell 6:

from sklearn.feature_selection import mutual_info_classif

## Cell 7:

train2 = train.copy()
test2 = test.copy()

## Cell 8:

def fe(df):
    df['alcohol_density'] = df['alcohol']  * df['density']
    df['alcohol_to_density'] = df['alcohol'] / df['density']
    df['sulphate/density'] = df['sulphates']  / df['density']

## Cell 9:

fe(train2)
fe(test2)

## Cell 10:

features1 = train2[train2.quality==3].columns.to_list()[0:11]
features2 = train2[train2.quality==3].columns.to_list()[12:15]
features = features1 + features2

## Cell 11:


train2 = train2.drop(columns=['residual sugar', 'chlorides', 'free sulfur dioxide', 'pH'])
test2 = test2.drop(columns=['residual sugar', 'chlorides', 'free sulfur dioxide', 'pH'])

## Cell 12:

features = test2.columns.to_list()

## Cell 13:

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
train2_scaled = scaler.fit_transform(train2[features])
df_train2_scaled = pd.DataFrame (train2_scaled, columns=features)
train2 = pd.concat([df_train2_scaled, train2.quality], axis=1)

## Cell 14:

from sklearn.manifold import TSNE

## Cell 15:


tsne_model = TSNE(perplexity=25, n_components=2, init='pca', n_iter=250, random_state=23)
df_tsne = tsne_model.fit_transform(train2[features])

df_tsne_te = tsne_model.fit_transform(test2[features])
df_TSNE_te = pd.DataFrame(df_tsne_te, columns=['tsne1', 'tsne2'])
df_TSNE_te['Id'] = test.index
df_TSNE_te = df_TSNE_te.set_index('Id')

## Cell 16:

df_tmp = pd.DataFrame(df_tsne, columns=['tsne1', 'tsne2'])
df_TSNE = pd.concat([df_tmp,train[conf.target]], axis=1)

df_TSNE = df_TSNE[(df_TSNE.quality == 4) | (df_TSNE.quality == 7)]

groups = df_TSNE.groupby(conf.target)


fig, ax = plt.subplots(figsize=(12, 12))
ax.margins(0.05)
for name, group in groups:
    ax.plot(group.tsne1, group.tsne2, marker='o', linestyle='', ms=12, label=name)
ax.legend()



plt.show()

## Cell 17:

df_tmp = train2.drop(columns=['quality'])
train3 = pd.concat([df_tmp, df_TSNE], axis=1)
test3 = pd.concat([test2, df_TSNE_te], axis=1)

## Cell 18:

from sklearn.metrics import cohen_kappa_score
from sklearn.model_selection import StratifiedKFold

from lightgbm.sklearn import LGBMClassifier
from catboost import CatBoostClassifier

from lightgbm import LGBMRegressor
import scipy as sp
from functools import partial

import optuna
import warnings
warnings.filterwarnings('ignore')

## Cell 19:

y = train3[conf.target]
X = train3.drop([conf.target], axis=1)

## Cell 20:

scores =[]

def find_out_params_model(trial):
    random_state = trial.suggest_int('random_state', 1000, 2000)
    n_splits = trial.suggest_int('n_splits', 8, 20)
    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=conf.random)
    my_model = LGBMClassifier(
        random_state = random_state
    )
    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):

        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train , y_valid = y.iloc[train_idx] , y.iloc[valid_idx]
        my_model.fit(
            X_train, y_train,
            eval_set= [(X_valid,y_valid)],
            early_stopping_rounds = 50,
            verbose=0
        )

        preds_valid = my_model.predict(X_valid)
        score = cohen_kappa_score(y_valid,  preds_valid, weights = "quadratic")
        scores.append(score)
    return np.mean(scores)

# Annotated Target Code:


study = optuna.create_study(direction="maximize")
study.optimize(find_out_params_model, n_trials=2)