# Executed Cells:
## Cell 1:

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

## Cell 2:

df = pd.read_csv('data/iris-data.csv')

## Cell 3:


df = df.dropna(subset=['petal_width_cm'])
df.info()

## Cell 4:

df['class'].replace(["Iris-setossa","versicolor"], ["Iris-setosa","Iris-versicolor"], inplace=True)
df['class'].value_counts()

## Cell 5:

final_df = df[df['class'] != 'Iris-virginica']

## Cell 6:

final_df.loc[final_df.sepal_length_cm < 1, ['sepal_length_cm']] = final_df['sepal_length_cm']*100
final_df.hist(column = 'sepal_length_cm',bins=20, figsize=(10,5))

## Cell 7:

final_df = final_df.drop(final_df[(final_df['class'] == "Iris-setosa") & (final_df['sepal_width_cm'] < 2.5)].index)

## Cell 8:

final_df['class'].replace(["Iris-setosa","Iris-versicolor"], [1,0], inplace=True)

## Cell 9:

inp_df = final_df.drop(final_df.columns[[4]], axis=1)
out_df = final_df.drop(final_df.columns[[0,1,2,3]], axis=1)

scaler = StandardScaler()
inp_df = scaler.fit_transform(inp_df)

X_train, X_test, y_train, y_test = train_test_split(inp_df, out_df, test_size=0.2, random_state=42)

## Cell 10:

X_tr_arr = X_train
X_ts_arr = X_test
y_tr_arr= y_train.values
y_ts_arr = y_test.values

## Cell 11:

def weightInitialization(n_features):
    w = np.zeros((1,n_features))
    b = 0
    return w,b

## Cell 12:

def sigmoid_activation(result):
    final_result = 1/(1+np.exp(-result))
    return final_result

## Cell 13:

def model_optimize(w, b, X, Y):
    m = X.shape[0]


    final_result = sigmoid_activation(np.dot(w,X.T)+b)
    Y_T = Y.T
    cost = (-1/m)*(np.sum((Y_T*np.log(final_result)) + ((1-Y_T)*(np.log(1-final_result)))))



    dw = (1/m)*(np.dot(X.T, (final_result-Y.T).T))
    db = (1/m)*(np.sum(final_result-Y.T))

    grads = {"dw": dw, "db": db}

    return grads, cost

## Cell 14:

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def initialize_params(dim):
    w = np.zeros((dim, 1))
    b = 0
    return w, b

def model_optimize(w, b, X, Y):
    m = X.shape[0]











    final_result = sigmoid(np.dot(w, X.T) + b)
    cost = (-1/m) * np.sum(Y.T * np.log(final_result) + (1 - Y.T) * np.log(1 - final_result))


    dw = (1/m) * np.dot(X.T, (final_result - Y.T).T)
    db = (1/m) * np.sum(final_result - Y.T)


    grads = {"dw": dw, "db": db}

    return grads, cost

def model_train(X, Y, num_iterations, learning_rate):
    costs = []
    w, b = initialize_params(X.shape[1])

    for i in range(num_iterations):
        grads, cost = model_optimize(w, b, X, Y)

        dw = grads["dw"]
        db = grads["db"]

        w = w - learning_rate * dw
        b = b - learning_rate * db

        if i % 100 == 0:
            costs.append(cost)
            print("Cost after iteration %i: %f" % (i, cost))

    params = {"w": w, "b": b}
    grads = {"dw": dw, "db": db}

    return params, grads, costs

## Cell 15:

def model_predict(w, b, X, Y, learning_rate, no_iterations):
    costs = []
    for i in range(no_iterations):

        grads, cost = model_optimize(w,b,X,Y)

        dw = grads["dw"]
        db = grads["db"]

        w = w - (learning_rate * (dw.T))
        b = b - (learning_rate * db)


        if (i % 100 == 0):
            costs.append(cost)



    coeff = {"w": w, "b": b}
    gradient = {"dw": dw, "db": db}

    return coeff, gradient, costs

## Cell 16:

def predict(final_pred, m):
    y_pred = np.zeros((1,m))
    for i in range(final_pred.shape[1]):
        if final_pred[0][i] > 0.5:
            y_pred[0][i] = 1
    return y_pred

# Annotated Target Code:
X_tr_arr: np.ndarray
X_ts_arr: np.ndarray
y_tr_arr: np.ndarray
y_ts_arr: np.ndarray



n_features = X_tr_arr.shape[1]
print('Number of Features', n_features)
w, b = weightInitialization(n_features)

coeff, gradient, costs = model_predict(w, b, X_tr_arr, y_tr_arr, learning_rate=0.0001,no_iterations=4500)

w = coeff["w"]
b = coeff["b"]
print('Optimized weights', w)
print('Optimized intercept',b)

final_train_pred = sigmoid_activation(np.dot(w,X_tr_arr.T)+b)
final_test_pred = sigmoid_activation(np.dot(w,X_ts_arr.T)+b)

m_tr =  X_tr_arr.shape[0]
m_ts =  X_ts_arr.shape[0]

y_tr_pred = predict(final_train_pred, m_tr)
print('Training Accuracy',accuracy_score(y_tr_pred.T, y_tr_arr))

y_ts_pred = predict(final_test_pred, m_ts)
print('Test Accuracy',accuracy_score(y_ts_pred.T, y_ts_arr))