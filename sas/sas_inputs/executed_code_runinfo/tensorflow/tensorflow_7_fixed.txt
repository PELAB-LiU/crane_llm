# Executed Cells:
## Cell 1:

import tensorflow as tf

import matplotlib.pyplot as plt
import numpy as np
from transformers import BertTokenizer, TFBertModel

## Cell 2:

try:
    tpu=tf.distribute.cluster_resolver.TCPClusterResolver()


    print("Device : ",tpu.master())
    tf.config.experimental_connect_to_cluster(tpu)

    tf.tpu.experimental.initialize_tpu_system(tpu)

    strategy=tf.distribute.experimental.TPUStrategy(tpu)

except:
    strategy=tf.distribute.get_strategy()


print("Number of replicas : ",strategy.num_replicas_in_sync)



print(tf.__version__)







## Cell 3:

import pandas as pd

train = pd.read_csv("data/train.csv")
train = train[:10]

## Cell 4:

model_name = 'bert-base-multilingual-cased'
tokenizer = BertTokenizer.from_pretrained(model_name)

## Cell 5:

def encode_sentence(s):
   tokens = list(tokenizer.tokenize(s))
   tokens.append('[SEP]')
   return tokenizer.convert_tokens_to_ids(tokens)

## Cell 6:

def bert_encode(hypotheses, premises, tokenizer):

  num_examples = len(hypotheses)

  sentence1 = tf.ragged.constant([
      encode_sentence(s)
      for s in np.array(hypotheses)])
  sentence2 = tf.ragged.constant([
      encode_sentence(s)
       for s in np.array(premises)])

  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]
  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)

  input_mask = tf.ones_like(input_word_ids).to_tensor()

  type_cls = tf.zeros_like(cls)
  type_s1 = tf.zeros_like(sentence1)
  type_s2 = tf.ones_like(sentence2)
  input_type_ids = tf.concat(
      [type_cls, type_s1, type_s2], axis=-1).to_tensor()

  inputs = {
      'input_word_ids': input_word_ids.to_tensor(),
      'input_mask': input_mask,
      'input_type_ids': input_type_ids}

  return inputs

## Cell 7:

train_input = bert_encode(train.premise.values, train.hypothesis.values, tokenizer)

## Cell 8:



max_len = train_input['input_word_ids'].shape[1]

from transformers import BertTokenizer, TFBertModel


def build_model():
    bert_encoder = TFBertModel.from_pretrained(model_name)
    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name="input_word_ids")
    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name="input_mask")
    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name="input_type_ids")

    embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]
    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])

    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)
    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    return model

## Cell 9:

with strategy.scope():
    model = build_model()
    model.summary()

# Annotated Target Code:
train: pd.DataFrame
train_input: dict


model.fit(train_input, train.label.values, epochs = 2, verbose = 1, batch_size = 64, validation_split = 0.2)