# Executed Cells:
## Cell 1:

import numpy as np
import pandas as pd
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
from sklearn.model_selection import train_test_split
import torch
from torch.utils.data import Dataset, DataLoader
import clip
from PIL import Image
from collections import Counter
from sklearn import preprocessing
from sklearn.preprocessing import OneHotEncoder




import os
seed=42

## Cell 2:


train_df=pd.read_csv("data_small/train.csv",index_col=0)

train_labels=train_df['label'].to_numpy()
train_labels=train_labels.reshape(train_labels.shape[0],1)


train_df=train_df.drop(columns=['label', 'label_type'])
test_df=pd.read_csv("data_small/test.csv",index_col=0)

test_labels=test_df['label'].to_numpy()
test_labels=test_labels.reshape(test_labels.shape[0],1)

test_df=test_df.drop(columns=('label'))
val_df = pd.read_csv("data_small/val.csv",index_col=0)

val_labels=val_df['label'].to_numpy()
val_labels=val_labels.reshape(val_labels.shape[0],1)

val_df = val_df.drop(columns=('label'))
vocab=np.append(train_labels,val_labels)

vocab=np.unique(vocab)
vocab=vocab.reshape(vocab.shape[0],1)
print(vocab.shape)
oh = OneHotEncoder(sparse_output=False)
hot_vocab=oh.fit_transform(vocab)
train_df.shape,val_df.shape,test_df.shape
train_df

## Cell 3:

train_arr=train_df.to_numpy()
train_arr=torch.from_numpy(train_arr)
test_arr=test_df.to_numpy()
test_arr=torch.from_numpy(test_arr)
val_arr=val_df.to_numpy()
val_arr=torch.from_numpy(val_arr)


train_labels=oh.transform(train_labels)
val_labels =oh.transform(val_labels)
test_enc_labels=[]
for i in range(test_labels.shape[0]):
    try:
        test_enc_labels.append(oh.transform(test_labels[i]))
    except ValueError as e:
        z=np.zeros((1,6294))
        test_enc_labels.append(z)
test_labels=np.array(test_enc_labels)
test_labels=np.squeeze(test_labels)
test_labels.shape

train_labels=torch.tensor(train_labels)
train_labels=train_labels.to(torch.float32)
val_labels=torch.tensor(val_labels)
val_labels=val_labels.to(torch.float32)
test_labels=torch.tensor(test_labels)
test_labels=test_labels.to(torch.float32)

## Cell 4:

class myDataset(Dataset):
    def __init__(self, array,labels):
        self.array = array.to(device)
        self.label = labels.to(device)


    def __getitem__(self, index):

        data=self.array[index]
        data=data.to(torch.float32)
        label=self.label[index].type(torch.float32)
        label=self.label[index].to(device)


        return data, label

    def __len__(self):
        return len(self.array)

## Cell 5:

device = "cuda" if torch.cuda.is_available() else "cpu"

## Cell 6:

customDataset=myDataset(train_arr,train_labels)
train_dataloader = DataLoader(customDataset, batch_size=64,shuffle=True, num_workers=0)

## Cell 7:


class AnswerModel(torch.nn.Module):

    def __init__(self):
        super(AnswerModel, self).__init__()

        self.norm0 = torch.nn.LayerNorm(1536).to(device)
        self.dropout0 = torch.nn.Dropout(0.5).to(device)
        self.linear1 = torch.nn.Linear(1536, 512).to(device)

        self.norm1 = torch.nn.LayerNorm(512).to(device)
        self.dropout1 = torch.nn.Dropout(0.5).to(device)

        self.activation = torch.nn.ReLU().to(device)

        self.linear2 = torch.nn.Linear(512 , 6294).to(device)

        self.aux = torch.nn.Linear(512,4).to(device)
        self.dropout1 = torch.nn.Dropout(0.5).to(device)
        self.gate = torch.nn.Linear(4, 6294).to(device)
        self.sigmoid=torch.nn.Sigmoid().to(device)


    def forward(self, x):
        x = self.norm0(x).to(device)
        x = self.dropout0(x).to(device)

        x= self.linear1(x).to(device)
        x = self.dropout1(x).to(device)

        xaux =self.aux(x).to(device)
        xaux =self.gate(xaux).to(device)
        vqa = self.linear2(x).to(device)
        out = vqa * self.sigmoid(xaux)
        return out,xaux
model= AnswerModel().to(device)
print(model)

## Cell 8:


def run_model(model,dataloader, optimizer,train = True ):
    if train:
        model.train()

    pred = []
    True_labels = []
    loss = torch.nn.CrossEntropyLoss()

    total_loss = 0
    for (data, label) in dataloader:

        data=data.to(device)
        label=label.to(device)




        optimizer.zero_grad()
        output,out_aux = model(data)
        output=output.type(torch.FloatTensor).to(device)
        out_aux=out_aux.type(torch.FloatTensor).to(device)



        loss_ = loss(output, label).to(device)
        loss_aux=loss(out_aux,label).to(device)
        mod_loss = loss_+loss_aux
        mod_loss.backward()
        total_loss+=mod_loss.item()

        optimizer.step()
        pred.append(output)
        True_labels.append(label)


    return pred ,True_labels, total_loss/len(dataloader)

# Annotated Target Code:
i: int


epoch = 2

optimizer = torch.optim.Adam(model.parameters(), 0.001, weight_decay=.01)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=.1, threshold=1e-6)

for e in range(epoch):
    pred,labels,loss = run_model(model,train_dataloader,optimizer)

    correct=0
    for i in range(len(pred)):
        predictions = pred[i].to(device)
        t_label = labels[i].to(device)
        position = torch.argmax(predictions).to(device)
        pos_label= torch.argmax(t_label).to(device)


        if (position == pos_label ):
            correct+=1
    scheduler.step(loss)
    print("epoch : ",e)
    print("training accuracy is ",correct/len(pred)*1.0)

    print(loss)